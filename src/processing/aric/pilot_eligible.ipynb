{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from lib.stats import demographic_characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify input paths from ARIC_NP server\n",
    "path_derive54: Path = Path(\n",
    "    \"Z:/DATA_NP/Visits/Visit 5/derive54_np.sas7bdat\"\n",
    ").resolve()  # Visit 5 on ARIC_NP server\n",
    "path_derive13: Path = Path(\n",
    "    \"Z:/DATA_NP/Visits/Visit 1/derive13_np.sas7bdat\"\n",
    ").resolve()  # Visit 1 on ARIC_NP server\n",
    "path_ncs51: Path = Path(\n",
    "    \"Z:/DATA_NP/Visits/Visit 5/derive_ncs51_np.sas7bdat\"\n",
    ").resolve()  # Visit 5 on ARIC_NP server\n",
    "path_mri: Path = Path(\n",
    "    \"Z:/DATA_NP/Visits/MultiVisit/V5_V11 Longitudinal MRI data/v5_v11_mri_derv_np_240221.sas7bdat\"\n",
    ").resolve()  # MultiVisit on ARIC_NP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify input paths\n",
    "path_population: Path = Path(\n",
    "    \"../../../data/original/aric/sample_selection/all_eleigible_samples_AS2021_25v3.xlsx\"\n",
    ").resolve()\n",
    "path_pilot: Path = Path(\n",
    "    \"../../../data/original/aric/ARIC_Pilot_Updated_06032022.csv\"\n",
    ").resolve()\n",
    "path_lipoprotein: Path = Path(\n",
    "    \"../../../data/original/aric/lipoproteins_6_29_23.csv\"\n",
    ").resolve()\n",
    "path_dictionary: Path = Path(\"../../../data/processed/aric/dictionary.csv\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify output paths\n",
    "path_output_lipoprotein_list: Path = Path(\n",
    "    \"../../../data/processed/aric/lipoprotein_list.csv\"\n",
    ").resolve()\n",
    "path_output_pilot: Path = Path(\"../../../data/processed/aric/pilot.csv\").resolve()\n",
    "path_output_demographic_characteristics: Path = Path(\n",
    "    \"../../../assets/tables/aric/demographic_characteristics.csv\"\n",
    ").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files from ARIC_NP server\n",
    "derive54: pd.DataFrame = pd.read_sas(\n",
    "    path_derive54, format=\"sas7bdat\", encoding=\"latin-1\"\n",
    ").convert_dtypes()\n",
    "derive13: pd.DataFrame = pd.read_sas(\n",
    "    path_derive13, format=\"sas7bdat\", encoding=\"latin-1\"\n",
    ").convert_dtypes()\n",
    "ncs51: pd.DataFrame = pd.read_sas(\n",
    "    path_ncs51, format=\"sas7bdat\", encoding=\"latin-1\"\n",
    ").convert_dtypes()\n",
    "mri: pd.DataFrame = pd.read_sas(\n",
    "    path_mri, format=\"sas7bdat\", encoding=\"latin-1\"\n",
    ").convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "population: pd.DataFrame = (\n",
    "    pd.read_excel(path_population, sheet_name=0, header=0)\n",
    "    .rename(columns={\"subjectid\": \"SubjectID\"})\n",
    "    .convert_dtypes()\n",
    ")\n",
    "pilot: pd.DataFrame = pd.read_csv(path_pilot)\n",
    "lipoprotein: pd.DataFrame = pd.read_csv(path_lipoprotein).convert_dtypes()\n",
    "dictionary: pd.DataFrame = (\n",
    "    pd.read_csv(path_dictionary)\n",
    "    .dropna(subset=[\"derive54_np\", \"derive13_np\", \"derive_ncs51_np\"], how=\"all\")\n",
    "    .convert_dtypes()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define inclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inclusion criteria\n",
    "# 1. have fasting unthawed plasma samples at V5\n",
    "population[\"criteria1\"] = (population[\"criteria1\"] == 1).astype(bool)\n",
    "\n",
    "# 2. were adjudicated CN or MCI at V5\n",
    "population[\"COGDIAG51\"] = pd.Categorical(\n",
    "    population[\"COGDIAG51\"], categories=[\"N\", \"M\", \"D\", \"U\"], ordered=True\n",
    ")\n",
    "population[\"cn_or_mci\"] = (population[\"COGDIAG51\"].isin([\"N\", \"M\"])).astype(bool)\n",
    "\n",
    "# 3. have brain MRI scans at V5\n",
    "ncs51[\"have_mri\"] = ncs51[\"ADSIGREGVOL51\"].notna()\n",
    "\n",
    "# 4. have amyloid PET data from ARIC-PET study\n",
    "population[\"criteria3\"] = (population[\"criteria3\"] == 1).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sets of SUBJECTIDs for each criteria\n",
    "c1: set[str] = set(population[\"SubjectID\"].loc[population[\"criteria1\"]])\n",
    "c2: set[str] = set(population[\"SubjectID\"].loc[population[\"cn_or_mci\"]])\n",
    "c3: set[str] = set(ncs51[\"SUBJECTID\"].loc[ncs51[\"have_mri\"]])\n",
    "c4: set[str] = set(population[\"SubjectID\"].loc[population[\"criteria3\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute included and excluded population using set operations\n",
    "id_eligible: set[str] = c1.intersection(c2, c3, c4)\n",
    "id_included: set[str] = set(lipoprotein[\"ID\"])\n",
    "id_excluded: set[str] = id_eligible.difference(id_included)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect data from ARIC server for excluded population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionaries that map variable names to their original names on the ARIC server\n",
    "dict_derive54: dict[str, str] = (\n",
    "    dictionary.dropna(subset=[\"derive54_np\"])\n",
    "    .set_index(\"variable_name\")[\"derive54_np\"]\n",
    "    .to_dict()\n",
    ")\n",
    "dict_derive13: dict[str, str] = (\n",
    "    dictionary.dropna(subset=[\"derive13_np\"])\n",
    "    .set_index(\"variable_name\")[\"derive13_np\"]\n",
    "    .to_dict()\n",
    ")\n",
    "dict_ncs51: dict[str, str] = (\n",
    "    dictionary.dropna(subset=[\"derive_ncs51_np\"])\n",
    "    .set_index(\"variable_name\")[\"derive_ncs51_np\"]\n",
    "    .to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data based on columns and samples\n",
    "df_excluded: pd.DataFrame = derive54.loc[\n",
    "    derive54[\"SUBJECTID\"].isin(id_excluded), list(dict_derive54.values())\n",
    "].reset_index(drop=True)\n",
    "df_excluded: pd.DataFrame = df_excluded.join(\n",
    "    derive13.set_index(\"SUBJECTID\")[dict_derive13.values()], on=\"SUBJECTID\", how=\"inner\"\n",
    ").join(ncs51.set_index(\"SUBJECTID\")[dict_ncs51.values()], on=\"SUBJECTID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label stage as included or excluded\n",
    "stage_list: list[str] = [\"included\", \"excluded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label excluded samples\n",
    "df_excluded[\"stage\"] = stage_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cholesterols and triglycerides, convert from SI unit mM to mg/dL\n",
    "for _, row in dictionary.dropna(subset=\"conversion_factor\").iterrows():\n",
    "    variable_name: str = row.loc[\"derive54_np\"]\n",
    "    df_excluded[variable_name] = (\n",
    "        df_excluded[variable_name] / row[\"conversion_factor\"]\n",
    "    ).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate existing pilot data with excluded population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the existing demographic data as the included population\n",
    "df_included: pd.DataFrame = pilot.loc[\n",
    "    pilot[\"SubjectID\"].isin(id_included)\n",
    "].convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename pilot columns to their original names in ARIC variable dictionary\n",
    "df_included: pd.DataFrame = (\n",
    "    df_included.rename(columns=dict_derive54)\n",
    "    .rename(columns=dict_derive13)\n",
    "    .rename(columns=dict_ncs51)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate included and excluded population, if the column is not in df_excluded, fill with NaN\n",
    "df_included[\"stage\"] = stage_list[0]\n",
    "df_concat = pd.concat([df_included, df_excluded], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join additional brain MRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify columns and visit code to use for MRI data\n",
    "usecols_mri: list[str] = [\n",
    "    \"EstimatedTotalIntraCranialVol\",\n",
    "    \"temporal_parietal_metaroi_vol\",\n",
    "]\n",
    "mri_v5: pd.DataFrame = mri.loc[mri[\"VISIT\"].isin([\"V5\"])].copy()\n",
    "mri_v7: pd.DataFrame = mri.loc[mri[\"VISIT\"].isin([\"V6V7\"])].copy()\n",
    "mri_v11: pd.DataFrame = mri.loc[mri[\"VISIT\"].isin([\"V8V11\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join MRI data to the concatenated data\n",
    "df: pd.DataFrame = (\n",
    "    df_concat.join(\n",
    "        mri_v5.set_index(\"SUBJECTID\")[usecols_mri], on=\"SUBJECTID\", how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        mri_v7.set_index(\"SUBJECTID\")[usecols_mri],\n",
    "        on=\"SUBJECTID\",\n",
    "        how=\"left\",\n",
    "        rsuffix=\"_V6V7\",\n",
    "    )\n",
    "    .join(\n",
    "        mri_v11.set_index(\"SUBJECTID\")[usecols_mri],\n",
    "        on=\"SUBJECTID\",\n",
    "        how=\"left\",\n",
    "        rsuffix=\"_V8V11\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanitize categorical variables\n",
    "df[\"stage\"] = pd.Categorical(df[\"stage\"], categories=stage_list, ordered=True)\n",
    "df[\"CURSMK52\"] = pd.Categorical(df[\"CURSMK52\"], categories=[0, 1], ordered=True)\n",
    "df[\"GENDER51\"] = pd.Categorical(df[\"GENDER51\"], categories=[\"F\", \"M\"], ordered=True)\n",
    "df[\"RACEGRP51\"] = pd.Categorical(\n",
    "    df[\"RACEGRP51\"], categories=[\"A\", \"B\", \"I\", \"W\"], ordered=True\n",
    ")\n",
    "df[\"CENTER\"] = pd.Categorical(\n",
    "    df[\"CENTER\"], categories=[\"F\", \"J\", \"M\", \"W\"], ordered=True\n",
    ")\n",
    "df[\"DIABTS54\"] = pd.Categorical(df[\"DIABTS54\"], categories=[0, 1], ordered=True)\n",
    "df[\"HYPERT55\"] = pd.Categorical(df[\"HYPERT55\"], categories=[0, 1], ordered=True)\n",
    "df[\"CHOLMDCODE53\"] = pd.Categorical(df[\"CHOLMDCODE53\"], categories=[0, 1], ordered=True)\n",
    "df[\"HYPTMDCODE52\"] = pd.Categorical(df[\"HYPTMDCODE52\"], categories=[0, 1], ordered=True)\n",
    "df[\"STATINCODE52\"] = pd.Categorical(df[\"STATINCODE52\"], categories=[0, 1], ordered=True)\n",
    "df[\"PRVCHD51\"] = pd.Categorical(df[\"PRVCHD51\"], categories=[0, 1], ordered=True)\n",
    "df[\"COGDIAG51\"] = pd.Categorical(\n",
    "    df[\"COGDIAG51\"], categories=[\"N\", \"U\", \"M\", \"D\"], ordered=True\n",
    ")\n",
    "df[\"ELEVEL02\"] = pd.Categorical(df[\"ELEVEL02\"], categories=[1, 2, 3], ordered=True)\n",
    "df[\"PREVDEFPOSSHF51\"] = pd.Categorical(\n",
    "    df[\"PREVDEFPOSSHF51\"], categories=[0, 1], ordered=True\n",
    ")\n",
    "df[\"PRVSTR51\"] = pd.Categorical(df[\"PRVSTR51\"], categories=[0, 1], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df[\"globalcortex\"] = df[\"globalcortex\"].fillna(0)\n",
    "df[\"FINAL_APOE\"] = df[\"FINAL_APOE\"].fillna(0)\n",
    "df[\"FINAL_APOE\"] = df[\"FINAL_APOE\"].astype(str).str.contains(\"4\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute demographic characteristics\n",
    "df_stat = demographic_characteristics(df, stage_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save demographic characteristics to CSV\n",
    "df_stat.to_csv(path_output_demographic_characteristics, index=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join lipoprotein data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of lipoproteins\n",
    "lipoprotein_list: list[str] = lipoprotein.columns[4:129].tolist()\n",
    "df_lipoprotein_list: pd.DataFrame = pd.DataFrame(\n",
    "    lipoprotein_list, columns=[\"lipoprotein\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for included samples\n",
    "df_demographics: pd.DataFrame = df.loc[df[\"stage\"] == \"included\"].drop(\n",
    "    columns=[\"stage\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join lipoprotein data\n",
    "df_merge: pd.DataFrame = df_demographics.join(\n",
    "    lipoprotein.set_index(\"ID\")[lipoprotein_list], on=\"SUBJECTID\", how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "df_lipoprotein_list.to_csv(path_output_lipoprotein_list, index=False)\n",
    "df_merge.to_csv(path_output_pilot, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
